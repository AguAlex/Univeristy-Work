# Clasificarea Semnalelor Accelerometru cu TensorFlow/Keras

## Descrierea Problemei

Acest proiect implementeazÄƒ o reÈ›ea neuronalÄƒ feed-forward folosind TensorFlow/Keras pentru a clasifica semnalele accelerometrului din datele de accelerometru pe 3 axe. Semnalele reprezintÄƒ valorile forÈ›ei G pe axele x, y, z pe o perioadÄƒ de 1.5 secunde, cu frecvenÈ›e de eÈ™antionare variabile.

### Structura Datelor
- **Date de antrenare**: 1000 de semnale cu etichete (0-3)
- **Date de test**: 400 de semnale fÄƒrÄƒ etichete
- **Format semnal**: Fiecare fiÈ™ier conÈ›ine 3 coloane (x, y, z) cu numÄƒr variabil de rÃ¢nduri
- **Etichete**: 4 clase (0, 1, 2, 3)

### CerinÈ›e
- AcurateÈ›e minimÄƒ 80% pentru 1 punct
- AcurateÈ›e minimÄƒ 85% pentru 2 puncte
- FoloseÈ™te optimizatorul Adam
- Maxim 3 straturi Ã®n reÈ›eaua feed-forward

## Implementarea SoluÈ›iei

### Caracteristici Principale

1. **Normalizarea Semnalelor**: Toate semnalele sunt normalizate la o lungime fixÄƒ (200 de eÈ™antioane) prin:
   - Trunchierea semnalelor mai lungi
   - Completarea semnalelor mai scurte cu zero-uri

2. **Arhitectura ReÈ›elei Neuronale**:
   - Strat de intrare: Semnal aplatizat (200 Ã— 3 = 600 caracteristici)
   - Strat ascuns 1: 256 de neuroni cu activare ReLU
   - Strat ascuns 2: 128 de neuroni cu activare ReLU
   - Strat de ieÈ™ire: 4 neuroni (cÃ¢te unul per clasÄƒ)
   - Normalizare batch È™i dropout pentru regularizare

3. **Strategia de Antrenare**:
   - Optimizator Adam cu rata de Ã®nvÄƒÈ›are 0.001
   - FuncÈ›ia de pierdere cross-entropy
   - Programare rate de Ã®nvÄƒÈ›are cu ReduceLROnPlateau
   - Early stopping bazat pe acurateÈ›ea de validare
   - ÃmpÄƒrÈ›ire 80/20 antrenare/validare

### FiÈ™iere

- `neural_network_tensorflow.py`: Implementarea principalÄƒ
- `requirements_tensorflow.txt`: DependenÈ›ele Python
- `predictions_tensorflow.txt`: PredicÈ›iile generate pentru setul de test
- `best_model_tensorflow.h5`: Ponderile modelului cel mai bun salvat
- `training_history.png`: Graficul istoricului de antrenare

## Utilizare

### Instalare

```bash
pip install -r requirements_tensorflow.txt
```

### Rularea SoluÈ›iei

```bash
python neural_network_tensorflow.py
```

### Rezultat

Scriptul va:
1. ÃncÄƒrca È™i preprocesa datele
2. Antrena reÈ›eaua neuronalÄƒ
3. AfiÈ™a progresul de antrenare pentru fiecare epocÄƒ
4. Salva cel mai bun model bazat pe acurateÈ›ea de validare
5. Genera predicÈ›ii pentru setul de test
6. Salva predicÈ›iile Ã®n `predictions_tensorflow.txt`
7. AfiÈ™a acurateÈ›ea finalÄƒ È™i punctele cÃ¢È™tigate

### Rezultate AÈ™teptate

Modelul obÈ›ine Ã®n mod tipic:
- **AcurateÈ›e de Validare**: 85-90%
- **Puncte**: 2 puncte (acurateÈ›e â‰¥ 85%)

## Detalii Tehnice

### Preprocesarea Datelor
- Normalizarea lungimii semnalului la 200 de eÈ™antioane
- Completarea cu zero-uri pentru semnalele mai scurte
- Trunchierea pentru semnalele mai lungi
- Conversia la array-uri NumPy

### Arhitectura Modelului
```python
Sequential([
  Flatten(input_shape=(200, 3)),
  Dense(256, activation='relu'),
  BatchNormalization(),
  Dropout(0.3),
  Dense(128, activation='relu'),
  BatchNormalization(),
  Dropout(0.3),
  Dense(4, activation='softmax')
])
```

### Parametrii de Antrenare
- **Epoci**: 100
- **Batch size**: 32
- **Rata de Ã®nvÄƒÈ›are**: 0.001
- **Dropout rate**: 0.3

## OptimizÄƒri de PerformanÈ›Äƒ

SoluÈ›ia include mai multe optimizÄƒri:
- Normalizare batch pentru convergenÈ›Äƒ mai rapidÄƒ
- Dropout pentru regularizare
- Programare rate de Ã®nvÄƒÈ›are
- Checkpointing model (salveazÄƒ cel mai bun model)
- Accelerare GPU cÃ¢nd este disponibilÄƒ
- Early stopping pentru a preveni overfitting-ul

## Evaluare

Modelul este evaluat pe un set de validare separat (20% din datele de antrenare) pentru a asigura o estimare de performanÈ›Äƒ fiabilÄƒ. AcurateÈ›ea finalÄƒ determinÄƒ punctele cÃ¢È™tigate:

- **â‰¥85%**: 2 puncte ğŸ‰
- **â‰¥80%**: 1 punct ğŸ‘
- **<80%**: 0 puncte âš ï¸

## Avantajele TensorFlow/Keras

1. **API simplu È™i intuitiv**: Keras oferÄƒ o interfaÈ›Äƒ uÈ™or de folosit
2. **Callbacks avansate**: Early stopping, checkpointing, learning rate scheduling
3. **Vizualizare integratÄƒ**: Istoricul de antrenare È™i grafice
4. **OptimizÄƒri automate**: TensorFlow optimizeazÄƒ automat performanÈ›a
5. **Compatibilitate GPU**: Suport nativ pentru accelerare GPU 